import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score
import matplotlib.pyplot as plt
import tensorflow as tf
import time
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Embedding
from gensim.models import Word2Vec
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score


# Load the CSV data
df = pd.read_csv('../../dataset.csv')

# Data Filtering
df = df[df['Length'] != 0]

grouped_df = df.groupby('File').agg({
    'Sequence': ' '.join,
    'Label': 'first'
}).reset_index()

#grouped_df, _ = train_test_split(grouped_df, test_size=0.997, random_state=42, stratify=grouped_df['Label'])

# Further split filtered_df based on 'File' column values
train_data, test_data = train_test_split(grouped_df, test_size=0.3, random_state=42, stratify=grouped_df['Label'])
test_data, validation_data = train_test_split(test_data, test_size=0.3, random_state=42, stratify=test_data['Label'])

print("Number of samples in dataframe:", len(grouped_df))
print("Number of samples in train_data:", len(train_data))
print("Number of samples in validation_data:", len(validation_data))
print("Number of samples in test_data:", len(test_data))
