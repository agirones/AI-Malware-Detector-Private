import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score
import matplotlib.pyplot as plt
import tensorflow as tf
import time
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Embedding
from gensim.models import Word2Vec
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score


# Load the CSV data
#df = pd.read_csv('../../dataset.csv')

# Data Filtering
#df = df[df['Length'] != 0]

#grouped_df = df.groupby('File').agg({
    #'Sequence': ' '.join,
    #'Label': 'first'
#}).reset_index()

#grouped_df, _ = train_test_split(grouped_df, test_size=0.997, random_state=42, stratify=grouped_df['Label'])

# Further split filtered_df based on 'File' column values
#train_data, test_data = train_test_split(grouped_df, test_size=0.3, random_state=42, stratify=grouped_df['Label'])
#test_data, validation_data = train_test_split(test_data, test_size=0.3, random_state=42, stratify=test_data['Label'])

#print("Number of samples in dataframe:", len(grouped_df))
#print("Number of samples in train_data:", len(train_data))
#print("Number of samples in validation_data:", len(validation_data))
#print("Number of samples in test_data:", len(test_data))

# Data Preprocessing
#tokenizer = Tokenizer()
#tokenizer.fit_on_texts(train_data['Sequence'])
#tokenizer.fit_on_texts(validation_data['Sequence'])
#train_word_sequences = tokenizer.sequences_to_texts(tokenizer.texts_to_sequences(train_data['Sequence']))
#train_word_sequences = [sequence.split() for sequence in train_word_sequences]
#validation_word_sequences = tokenizer.sequences_to_texts(tokenizer.texts_to_sequences(validation_data['Sequence']))
#validation_word_sequences = [sequence.split() for sequence in validation_word_sequences]

#embedding = Word2Vec(sentences=train_word_sequences + validation_word_sequences, vector_size=300, min_count=0, window=100, sg=1)
#embedding.save("word2vec.model")

embedding = Word2Vec.load("word2vec.model")


#validation_sequences_tokenized = tokenizer.texts_to_sequences(validation_data['Sequence'])
#test_sequences_tokenized = tokenizer.texts_to_sequences(test_data['Sequence'])

def compute_embeddings(sequence, embedding_model):
    tokenizer = Tokenizer()
    tokenizer.fit_on_texts(sequence.split())
    word_counts = tokenizer.word_counts
    sorted_word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)
    top_frequent_words = [word_count[0] for word_count in sorted_word_counts[:600]]
    embeddings = [embedding_model.wv[word] for word in top_frequent_words]
    return embeddings

def compute_test_embeddings(sequence, embedding_model):
    tokenizer = Tokenizer()
    tokenizer.fit_on_texts(sequence.split())
    word_counts = tokenizer.word_counts
    sorted_word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)
    top_frequent_words = [word_count[0] for word_count in sorted_word_counts[:600]]
    embeddings = [embedding_model.wv[word] for word in top_frequent_words if word in embedding_model.wv]
    return embeddings

#train_data['Embedding'] = train_data['Sequence'].apply(lambda x: compute_embeddings(x, embedding))
#validation_data['Embedding'] = validation_data['Sequence'].apply(lambda x: compute_embeddings(x, embedding))
#test_data['Embedding'] = test_data['Sequence'].apply(lambda x: compute_test_embeddings(x, embedding))

#train_data.to_pickle("precomputed_embeddings_train_data.plk")
#validation_data.to_pickle("precomputed_embeddings_validation_data.plk")
#test_data.to_pickle("precomputed_embeddings_test_data.plk")

train_data = pd.read_pickle("precomputed_embeddings_train_data.plk")
validation_data = pd.read_pickle("precomputed_embeddings_validation_data.plk")
test_data = pd.read_pickle("precomputed_embeddings_test_data.plk")

print("Number of samples in dataframe:", len(train_data) + len(validation_data) + len(test_data))
print("Number of samples in train_data:", len(train_data))
print("Number of samples in validation_data:", len(validation_data))
print("Number of samples in test_data:", len(test_data))


def train_generator():
    for embedding, label in zip(train_data['Embedding'], train_data['Label']):
        yield embedding, label

def validation_generator():
    for embedding, label in zip(validation_data['Embedding'], validation_data['Label']):
        yield embedding, label

def test_generator():
    for embedding, label in zip(test_data['Embedding'], test_data['Label']):
        yield embedding, label

# Create tf.data.Dataset from RaggedTensors
train_dataset = tf.data.Dataset.from_generator(
        train_generator,
        output_signature=(
            tf.TensorSpec(shape=(None,300), dtype=tf.float16),
            tf.TensorSpec(shape=(), dtype=tf.float16)
            )
    )

validation_dataset = tf.data.Dataset.from_generator(
        validation_generator,
        output_signature=(
            tf.TensorSpec(shape=(None,300), dtype=tf.float16),
            tf.TensorSpec(shape=(), dtype=tf.float16)
            )
    )

test_dataset = tf.data.Dataset.from_generator(
        test_generator,
        output_signature=(
            tf.TensorSpec(shape=(None,300), dtype=tf.float16),
            tf.TensorSpec(shape=(), dtype=tf.float16)
            )
    )

# Shuffle and batch the datasets
train_dataset = train_dataset.shuffle(128).padded_batch(64)
validation_dataset = validation_dataset.shuffle(128).padded_batch(64)
test_dataset = test_dataset.padded_batch(64)

# Build the LSTM model
model = Sequential()
model.add(Bidirectional(LSTM(units=64, dropout=0.2)))
#model.add(LSTM(64, input_shape=(None, 1)))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model using tf.data.Dataset
history = model.fit(train_dataset, epochs=50, batch_size=64, validation_data=validation_dataset, verbose=2)
model.save('model')
np.save('history.npy', history.history)

# Plot training and validation loss
# Increase the figure size for better visibility
plt.figure(figsize=(14, 7))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()

plt.suptitle("Training and Validation Metrics over Epochs", y=0.95)
plt.subplots_adjust(wspace=0.3)

plt.savefig('validation_graph.png', dpi=1200)

# Evaluate the model using tf.data.Dataset
y_pred_probs = model.predict(test_dataset, verbose=2)
y_pred = (y_pred_probs > 0.5).astype(int)
y_true = test_data['Label'].to_list()

accuracy = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)
f1 = f1_score(y_true, y_pred)

fpr, tpr, thresholds = roc_curve(y_true, y_pred_probs)
roc_auc = roc_auc_score(y_true, y_pred_probs)

# Print metrics
print()
print("Testing:")
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)
print("ROC AUC:", roc_auc)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc='lower right')

plt.savefig('roc_curve.png', dpi=1200)
