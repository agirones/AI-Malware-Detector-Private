import tensorflow as tf
import keras_tuner as kt
import pandas as pd
from sklearn.model_selection import train_test_split


class HyperHyperband(kt.HyperModel):
    def build(self, hp):
        model = tf.keras.Sequential()
        num_layers = hp.Int("num_layers", 0, 2)
        for i in range(num_layers):
            model.add(
                    tf.keras.layers.Bidirectional(
                        tf.keras.layers.LSTM(
                            units=hp.Int(f"units_{i}", 1, 320), 
                            dropout=hp.Choice("dropout", [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]),
                            return_sequences=True
                            )
                        )
                    )
        model.add(tf.keras.layers.Bidirectional(
                tf.keras.layers.LSTM(
                    units=hp.Int(f"units_{num_layers}", 1, 320)
                    )
                )
              )
        model.add(tf.keras.layers.Dense(1, activation='sigmoid'))
        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
        return model
    def fit(self, hp, model, train_dataset, validation_data, **kwargs):
        history = model.fit(train_dataset,
                            epochs=hp.Int("epochs", 1, 100),
                            batch_size=hp.Int("batch_size", 1, 256),
                            validation_data=validation_data,
                            verbose=2,
                            )
        return history


tuner = kt.Hyperband(
    hypermodel=HyperHyperband(),
    objective=kt.Objective("val_accuracy", "max"),
    max_epochs=100,
    factor=3,
    directory="hpo",
    project_name="tfm",
)

dataset = pd.read_pickle("precomputed_embeddings_all_data.plk")
dataset, test_data = train_test_split(dataset, test_size=0.1, random_state=42, stratify=dataset['Label'])
#ds, _ = train_test_split(dataset, test_size=0.995, random_state=42, stratify=dataset['Label'])
train_data, validation_data = train_test_split(dataset, test_size=0.1, random_state=42, stratify=dataset['Label'])
#train_data, validation_data = train_test_split(ds, test_size=0.2, random_state=42, stratify=ds['Label'])

def train_generator():
    for embedding, label in zip(train_data['Embedding'], train_data['Label']):
        yield embedding, label

def validation_generator():
    for embedding, label in zip(validation_data['Embedding'], validation_data['Label']):
        yield embedding, label


train_dataset = tf.data.Dataset.from_generator(
        train_generator,
        output_signature=(
            tf.TensorSpec(shape=(None,300), dtype=tf.float16),
            tf.TensorSpec(shape=(), dtype=tf.float16)
            )
    )

validation_dataset = tf.data.Dataset.from_generator(
        validation_generator,
        output_signature=(
            tf.TensorSpec(shape=(None,300), dtype=tf.float16),
            tf.TensorSpec(shape=(), dtype=tf.float16)
            )
    )

train_dataset = train_dataset.shuffle(128).padded_batch(64)
validation_dataset = validation_dataset.shuffle(128).padded_batch(64)

tuner.search(train_dataset, epochs=2, validation_data=validation_dataset,
            callbacks=[tf.keras.callbacks.TensorBoard(f"{tuner.project_dir}/tb_logs")])

