import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score
import matplotlib.pyplot as plt
import tensorflow as tf
import time
from sklearn.model_selection import StratifiedKFold
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Embedding
from gensim.models import Word2Vec
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score
from lstm_model import LSTMModel


# Load the CSV data
#df = pd.read_csv('../../dataset.csv')

# Data Filtering
#df = df[df['Length'] != 0]

#dataset = df.groupby('File').agg({
#    'Sequence': ' '.join,
#    'Label': 'first'
#}).reset_index()

#dataset, _ = train_test_split(dataset, test_size=0.98, random_state=42, stratify=dataset['Label'])

# Data Preprocessing
#tokenizer = Tokenizer()
#tokenizer.fit_on_texts(dataset['Sequence'])
#word_sequences = tokenizer.sequences_to_texts(tokenizer.texts_to_sequences(dataset['Sequence']))
#word_sequences = [sequence.split() for sequence in word_sequences]

#embedding = Word2Vec(sentences=word_sequences, vector_size=300, min_count=0, window=100, sg=1)
#embedding.save("word2vec.model.cv")

embedding = Word2Vec.load("word2vec.model.cv")

def compute_embeddings(sequence, embedding_model):
    tokenizer = Tokenizer()
    tokenizer.fit_on_texts(sequence.split())
    word_counts = tokenizer.word_counts
    sorted_word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)
    top_frequent_words = [word_count[0] for word_count in sorted_word_counts[:600]]
    embeddings = [embedding_model.wv[word] for word in top_frequent_words]
    return embeddings

#dataset['Embedding'] = dataset['Sequence'].apply(lambda x: compute_embeddings(x, embedding))

#dataset.to_pickle("precomputed_embeddings_all_data.plk")

dataset = pd.read_pickle("precomputed_embeddings_all_data.plk")

num_folds = 10
kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)

def train_generator():
    for index in train_index:
        embedding = dataset['Embedding'].iloc[index]
        label = dataset['Label'].iloc[index]
        yield embedding, label

def validation_generator():
    for index in validation_index:
        embedding = dataset['Embedding'].iloc[index]
        label = dataset['Label'].iloc[index]
        yield embedding, label

y_pred_probs = []
y_pred = []
y_true = []

for train_index, validation_index in kfold.split(dataset['Embedding'], dataset['Label']):

    train_dataset = tf.data.Dataset.from_generator(
            train_generator,
            output_signature=(
                tf.TensorSpec(shape=(None,300), dtype=tf.float16),
                tf.TensorSpec(shape=(), dtype=tf.float16)
                )
        )
    
    validation_dataset = tf.data.Dataset.from_generator(
            validation_generator,
            output_signature=(
                tf.TensorSpec(shape=(None,300), dtype=tf.float16),
                tf.TensorSpec(shape=(), dtype=tf.float16)
                )
        )
    train_dataset = train_dataset.padded_batch(64)
    validation_dataset = validation_dataset.padded_batch(64)

    model = LSTMModel(depth=1, bidirectional=True, num_neurons=64, dropout_rate=0.2, weight_update_algorithm='adam')
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    model.fit(train_dataset, epochs=25, batch_size=64, verbose=0)

    fold_pred_probs = model.predict(validation_dataset, verbose=0).flatten().tolist()
    y_pred_probs.extend(fold_pred_probs)
    y_pred.extend([1 if prob > 0.5 else 0 for prob in fold_pred_probs])
    y_true.extend(dataset['Label'].iloc[validation_index].to_list())

accuracy = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)
f1 = f1_score(y_true, y_pred)

fpr, tpr, thresholds = roc_curve(y_true, y_pred_probs)
roc_auc = roc_auc_score(y_true, y_pred_probs)

# Print metrics
print()
print("Testing:")
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)
print("ROC AUC:", roc_auc)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc='lower right')

plt.savefig('cv_roc_curve.png', dpi=1200)
